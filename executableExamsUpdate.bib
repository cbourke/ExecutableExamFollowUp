

@inproceedings{10.1145/3545945.3569724,
  author = {Bourke, Chris and Erez, Yael and Hazzan, Orit},
  title = {Executable Exams: Taxonomy, Implementation and Prospects},
  year = {2023},
  isbn = {9781450394314},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3545945.3569724},
  doi = {10.1145/3545945.3569724},
  abstract = {Traditionally exams in introductory programming courses have tended to be multiple choice, or "paper-based" coding exams in which students hand write code. This does not reflect how students typically write and are assessed on programming assignments in which they write code on a computer and are able to validate and assess their code using an auto-grading system.Executable exams are exams in which students are given programming problems, write code using a computer within a development environment and submissions are digitally validated or executed. This format is far more consistent with how students engage in programming assignments.This paper explores the executable exam format and attempts to gauge the state-of-the-practice and how prevalent it is. First, we formulate a taxonomy of characteristics of executable exams, identifying common aspects and various levels of flexibility. then give two case studies: one in which executable exams have been utilized for nearly 10 years and another in which they've been recently adopted. Finally, we provide results from faculty surveys providing evidence that, though not standard practice, the use of executable exams is not uncommon and appears to be on the rise.},
  booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
  pages = {381–387},
  numpages = {7},
  keywords = {assessment, autograder, executable exams, introductory computer science, paper-based exams, taxonomy},
  location = {Toronto ON, Canada},
  series = {SIGCSE 2023}
}

%%% 3 papers cited our original SIGCSE23 paper:

@InProceedings{10.1007/978-981-99-8031-4_17,
  author="Rivera-Alvarado, Ernesto and Guadamuz, Sa{\'u}l",
  editor="Nagar, Atulya K.
  and Jat, Dharm Singh
  and Mishra, Durgesh
  and Joshi, Amit",
  title="A Proposal for a Standard Evaluation Method for Assessing Programming Proficiency in Assembly Language",
  booktitle="Intelligent Sustainable Systems",
  year="2024",
  publisher="Springer Nature Singapore",
  address="Singapore",
  pages="183--192",
  abstract="It is common knowledge that assembly language programming is a skill that students consider to be ``hard to learn''. Nonetheless, it is vastly required in several knowledge areas in engineering and technology. Several research efforts have addressed different methodologies for teaching assembly language to college students. While some provide interesting approaches to presenting the concepts, the studies still need a formal evaluation to discern if the proposal is objectively better at teaching than conventional classroom approaches. In assessing different methodologies for teaching assembly, we found the task to be more complex than expected, as we could not find a standard test that measures the ability of assembly programming. A written exam or evaluation could be used to measure proficiency in programming, but the efficacy of that test to evaluate real programming skills is a question to be answered. With this research, we would like to propose a design methodology for assessing programming skills in assembly language. Furthermore, we hope that this methodology can be used to create tests that can evaluate the programming skill in assembly language and could be used for testing the effectiveness of different teaching methods.",
  isbn="978-981-99-8031-4",
  notes = {cited our SIGCSE23 paper}
}

@misc{malmi2024computingspecificpedagogiestheoreticalmodels,
      title={Computing-specific pedagogies and theoretical models: common uses and relationships},
      author={Lauri Malmi and Judy Sheard and Claudia Szabo and Päivi Kinnunen},
      year={2024},
      eprint={2409.12245},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2409.12245},
      notes = {cited our SIGCSE23 paper}
}

@INPROCEEDINGS{asee_peer_46619,
  author = "Zulal Sevkli",
  title = "Assessing the Impact of Open-Resource Access on Student Performance in Computer-Based Examinations ",
  booktitle = "2024 ASEE Annual Conference \& Exposition",
  year = "2024",
  month = "June",
  address = "Portland, Oregon",
  publisher = "ASEE Conferences",
  note = {https://peer.asee.org/46619},
  number = {10.18260/1-2--46619},
  notes = {cited our SIGCSE23 paper}
}
